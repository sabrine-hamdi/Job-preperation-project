{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Prediction of Potential of Players",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL8mta6qNw0j"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sbn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQd0tGJ5bIsI",
        "outputId": "13cc0dd6-1f87-4662-a102-514a884fc2f5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT_kh7J5Nw0q",
        "outputId": "e4b8ef49-d26b-451f-cdbc-ea7d4d4d1567"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data.csv')\n",
        "print(\"rows = \", df.shape[0])\n",
        "print(\"columns = \", df.shape[1])\n",
        "print(\"total elements = \", df.size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rows =  18207\n",
            "columns =  89\n",
            "total elements =  1620423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0CWqthXNw0r"
      },
      "source": [
        "Dropping unnecessary columns for better predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcqdlB1nNw0r",
        "outputId": "85a7a912-03ed-4ed2-8905-f075f9191ea9"
      },
      "source": [
        "df = df.drop([\"Unnamed: 0\", \"ID\", \"Photo\",\"Nationality\",\"Flag\",\"Club\",\"Club Logo\",\"Value\",\"Wage\",\"Release Clause\",\"Special\",\n",
        "              \"International Reputation\",\"Work Rate\",\"Jersey Number\",\"Body Type\",\"Real Face\",\"Joined\",\"Loaned From\",\n",
        "              \"Contract Valid Until\",\"LS\",\"ST\",\"RS\",\"LW\",\"LF\",\"CF\",\"RF\",\"RW\",\"LAM\",\"CAM\",\"RAM\",\"LM\",\"LCM\",\"CM\",\"RCM\",\"RM\",\"LWB\",\n",
        "              \"LDM\",\"CDM\",\"RDM\",\"RWB\",\"LB\",\"LCB\",\"CB\",\"RCB\",\"RB\"], axis=1)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     Name  Age  Overall  ...  GKKicking GKPositioning  GKReflexes\n",
            "0                L. Messi   31       94  ...       15.0          14.0         8.0\n",
            "1       Cristiano Ronaldo   33       94  ...       15.0          14.0        11.0\n",
            "2               Neymar Jr   26       92  ...       15.0          15.0        11.0\n",
            "3                  De Gea   27       91  ...       87.0          88.0        94.0\n",
            "4            K. De Bruyne   27       91  ...        5.0          10.0        13.0\n",
            "...                   ...  ...      ...  ...        ...           ...         ...\n",
            "18202        J. Lundstram   19       47  ...        7.0           8.0         9.0\n",
            "18203  N. Christoffersson   19       47  ...        9.0           5.0        12.0\n",
            "18204           B. Worman   16       47  ...       10.0           6.0        13.0\n",
            "18205      D. Walker-Rice   17       47  ...       14.0           8.0         9.0\n",
            "18206           G. Nugent   16       46  ...        9.0          12.0         9.0\n",
            "\n",
            "[18207 rows x 44 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeU1WUcsNw0s"
      },
      "source": [
        "Display the number of nulls per column. This will determine how many incomplete rows of data exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6dM76U2Nw0s",
        "outputId": "62ed5ecd-581b-4c63-c991-b612a7a8dbac"
      },
      "source": [
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name                0\n",
            "Age                 0\n",
            "Overall             0\n",
            "Potential           0\n",
            "Preferred Foot     48\n",
            "Weak Foot          48\n",
            "Skill Moves        48\n",
            "Position           60\n",
            "Height             48\n",
            "Weight             48\n",
            "Crossing           48\n",
            "Finishing          48\n",
            "HeadingAccuracy    48\n",
            "ShortPassing       48\n",
            "Volleys            48\n",
            "Dribbling          48\n",
            "Curve              48\n",
            "FKAccuracy         48\n",
            "LongPassing        48\n",
            "BallControl        48\n",
            "Acceleration       48\n",
            "SprintSpeed        48\n",
            "Agility            48\n",
            "Reactions          48\n",
            "Balance            48\n",
            "ShotPower          48\n",
            "Jumping            48\n",
            "Stamina            48\n",
            "Strength           48\n",
            "LongShots          48\n",
            "Aggression         48\n",
            "Interceptions      48\n",
            "Positioning        48\n",
            "Vision             48\n",
            "Penalties          48\n",
            "Composure          48\n",
            "Marking            48\n",
            "StandingTackle     48\n",
            "SlidingTackle      48\n",
            "GKDiving           48\n",
            "GKHandling         48\n",
            "GKKicking          48\n",
            "GKPositioning      48\n",
            "GKReflexes         48\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbDv_nhuNw0t"
      },
      "source": [
        "Remove all rows with nulls. Then re-display the number of nulls per column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfjaykuFNw0t",
        "outputId": "6ae04e54-6567-406a-e5d0-ed3c79cf6035"
      },
      "source": [
        "df = df.dropna()\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name               0\n",
            "Age                0\n",
            "Overall            0\n",
            "Potential          0\n",
            "Preferred Foot     0\n",
            "Weak Foot          0\n",
            "Skill Moves        0\n",
            "Position           0\n",
            "Height             0\n",
            "Weight             0\n",
            "Crossing           0\n",
            "Finishing          0\n",
            "HeadingAccuracy    0\n",
            "ShortPassing       0\n",
            "Volleys            0\n",
            "Dribbling          0\n",
            "Curve              0\n",
            "FKAccuracy         0\n",
            "LongPassing        0\n",
            "BallControl        0\n",
            "Acceleration       0\n",
            "SprintSpeed        0\n",
            "Agility            0\n",
            "Reactions          0\n",
            "Balance            0\n",
            "ShotPower          0\n",
            "Jumping            0\n",
            "Stamina            0\n",
            "Strength           0\n",
            "LongShots          0\n",
            "Aggression         0\n",
            "Interceptions      0\n",
            "Positioning        0\n",
            "Vision             0\n",
            "Penalties          0\n",
            "Composure          0\n",
            "Marking            0\n",
            "StandingTackle     0\n",
            "SlidingTackle      0\n",
            "GKDiving           0\n",
            "GKHandling         0\n",
            "GKKicking          0\n",
            "GKPositioning      0\n",
            "GKReflexes         0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41jaeMNLNw0t"
      },
      "source": [
        "Remove the lbs from the weight column. Then re-display the dataframe to show this worked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSEFVlqcNw0u",
        "outputId": "50737a41-940c-43ee-8880-11a2e121d044"
      },
      "source": [
        "df.Weight = df.Weight.str.replace('lbs', '')\n",
        "print(df.Weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        159\n",
            "1        183\n",
            "2        150\n",
            "3        168\n",
            "4        154\n",
            "        ... \n",
            "18202    134\n",
            "18203    170\n",
            "18204    148\n",
            "18205    154\n",
            "18206    176\n",
            "Name: Weight, Length: 18147, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR75ZajhNw0u"
      },
      "source": [
        "Convert the height column to cm. A function, height_convert, is already given below. Use Pandas' \"apply\" to apply this function to change each element in the Height column. Then re-display the dataframe to show this worked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDwxd0lgNw0u"
      },
      "source": [
        "def height_convert( value ):\n",
        "    try:\n",
        "        height = value.split('\\'')\n",
        "        feet = int(height[0])\n",
        "        inches = int(height[1])\n",
        "        return feet * 30.48 + inches * 2.54\n",
        "    except:\n",
        "        return np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tjoBzIdNw0v",
        "outputId": "6567a0d0-d7b8-4203-eebe-44560b619e7c"
      },
      "source": [
        "df[['Height']] = df.Height.apply(height_convert)\n",
        "print(df['Height'].round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        170.0\n",
            "1        188.0\n",
            "2        175.0\n",
            "3        193.0\n",
            "4        180.0\n",
            "         ...  \n",
            "18202    175.0\n",
            "18203    190.0\n",
            "18204    173.0\n",
            "18205    178.0\n",
            "18206    178.0\n",
            "Name: Height, Length: 18147, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFw2G_oiNw0v"
      },
      "source": [
        "Convert the weight column to Kg."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLmlFUITNw0v"
      },
      "source": [
        "def weight_convert( value ):\n",
        "    try:\n",
        "        lbs = int(value)\n",
        "        return lbs * 0.45359237\n",
        "    except:\n",
        "        return np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHfFqRmENw0v",
        "outputId": "b42ae7cb-4dfb-4c5f-84db-605f41665bde"
      },
      "source": [
        "df[['Weight']] = df.Weight.apply(weight_convert)\n",
        "print(df['Weight'].round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        72.0\n",
            "1        83.0\n",
            "2        68.0\n",
            "3        76.0\n",
            "4        70.0\n",
            "         ... \n",
            "18202    61.0\n",
            "18203    77.0\n",
            "18204    67.0\n",
            "18205    70.0\n",
            "18206    80.0\n",
            "Name: Weight, Length: 18147, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVMMYnCNw0w"
      },
      "source": [
        "Encode the values of the column Preferred Foot with '0' : Left and '1' : Right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xvM0hVYNw0w",
        "outputId": "d0246021-8af5-4d0c-fd8e-b197b26603e3"
      },
      "source": [
        "from sklearn import preprocessing   \n",
        "\n",
        "encoder = preprocessing.LabelEncoder()    \n",
        "df[\"Preferred Foot\"] = encoder.fit_transform(df.iloc[:,4])\n",
        "print(df[\"Preferred Foot\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        0\n",
            "1        1\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "18202    1\n",
            "18203    1\n",
            "18204    1\n",
            "18205    1\n",
            "18206    1\n",
            "Name: Preferred Foot, Length: 18147, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kItSpzXZNw0w"
      },
      "source": [
        "Define the input X and the output Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89uWWtn6Nw0x"
      },
      "source": [
        "x = df[[\"Preferred Foot\",\"Age\",\"Overall\",\"Weak Foot\"]]\n",
        "\n",
        "y = df[\"Potential\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFPc3wzNw0x"
      },
      "source": [
        "Split the data into training set and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Unvtj5gNw0x"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.3, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an3itW0UNw0x"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler  # Standardize features by removing the mean and scaling to unit variance\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4gc1s7uNw0z"
      },
      "source": [
        "Set the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8yvjVx8Nw00"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential  # Sequential = groups a linear stack of layers into a tf.keras.Model.\n",
        "                                     #              provides training and inference features on this model.\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1UFknMtNw00"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTOGiwWQgwxA"
      },
      "source": [
        "model.add(Dense(units=6,activation='relu'))\n",
        "model.add(Dense(units=18,activation='relu'))\n",
        "model.add(Dense(units=18,activation='relu'))\n",
        "model.add(Dense(units=12,activation='relu'))\n",
        "model.add(Dense(units=1,activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9di3a59khqZ8"
      },
      "source": [
        "model.compile(optimizer='adam',loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2edqp19-iLTs",
        "outputId": "8fbe2403-1e98-4d11-a63d-b99ffd097d25"
      },
      "source": [
        "model.fit(x=x_train,y=y_train,validation_data=(x_test,y_test),batch_size=250,epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "51/51 [==============================] - 22s 13ms/step - loss: 5108.1231 - val_loss: 4923.6128\n",
            "Epoch 2/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4758.4848 - val_loss: 3762.4456\n",
            "Epoch 3/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3060.1760 - val_loss: 989.9595\n",
            "Epoch 4/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 755.4289 - val_loss: 281.7326\n",
            "Epoch 5/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 232.3393 - val_loss: 130.7238\n",
            "Epoch 6/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 122.5154 - val_loss: 98.6020\n",
            "Epoch 7/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 96.6987 - val_loss: 77.1077\n",
            "Epoch 8/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 75.0764 - val_loss: 59.9586\n",
            "Epoch 9/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 58.6839 - val_loss: 46.5513\n",
            "Epoch 10/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 46.5460 - val_loss: 36.3838\n",
            "Epoch 11/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 36.7898 - val_loss: 28.8227\n",
            "Epoch 12/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 29.1679 - val_loss: 23.2511\n",
            "Epoch 13/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 23.8553 - val_loss: 19.3995\n",
            "Epoch 14/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 19.8556 - val_loss: 16.6302\n",
            "Epoch 15/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 16.5511 - val_loss: 14.7091\n",
            "Epoch 16/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 14.8623 - val_loss: 13.1647\n",
            "Epoch 17/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 13.4095 - val_loss: 12.0114\n",
            "Epoch 18/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 12.2038 - val_loss: 11.0840\n",
            "Epoch 19/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 11.3099 - val_loss: 10.3326\n",
            "Epoch 20/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 10.5789 - val_loss: 9.7390\n",
            "Epoch 21/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 9.8109 - val_loss: 9.2578\n",
            "Epoch 22/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 9.5159 - val_loss: 8.8154\n",
            "Epoch 23/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 8.9580 - val_loss: 8.4339\n",
            "Epoch 24/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.4072 - val_loss: 8.0663\n",
            "Epoch 25/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 8.2800 - val_loss: 7.7863\n",
            "Epoch 26/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 7.8909 - val_loss: 7.5007\n",
            "Epoch 27/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 7.6413 - val_loss: 7.2567\n",
            "Epoch 28/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 7.4699 - val_loss: 6.9846\n",
            "Epoch 29/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 7.3325 - val_loss: 6.7889\n",
            "Epoch 30/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 6.7205 - val_loss: 6.6120\n",
            "Epoch 31/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 6.6727 - val_loss: 6.4419\n",
            "Epoch 32/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.5108 - val_loss: 6.2572\n",
            "Epoch 33/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 6.2980 - val_loss: 6.1325\n",
            "Epoch 34/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 6.3511 - val_loss: 5.9656\n",
            "Epoch 35/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.1281 - val_loss: 5.8371\n",
            "Epoch 36/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 6.0766 - val_loss: 5.6718\n",
            "Epoch 37/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 5.7367 - val_loss: 5.5373\n",
            "Epoch 38/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 5.7961 - val_loss: 5.4472\n",
            "Epoch 39/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 5.4904 - val_loss: 5.2447\n",
            "Epoch 40/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 5.3413 - val_loss: 5.1580\n",
            "Epoch 41/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 5.2346 - val_loss: 4.9914\n",
            "Epoch 42/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 5.2468 - val_loss: 4.8551\n",
            "Epoch 43/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 5.0257 - val_loss: 4.7673\n",
            "Epoch 44/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.7879 - val_loss: 4.6842\n",
            "Epoch 45/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.7846 - val_loss: 4.5349\n",
            "Epoch 46/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.6381 - val_loss: 4.4269\n",
            "Epoch 47/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.4990 - val_loss: 4.3682\n",
            "Epoch 48/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.4180 - val_loss: 4.2702\n",
            "Epoch 49/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.4297 - val_loss: 4.1869\n",
            "Epoch 50/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.3150 - val_loss: 4.1192\n",
            "Epoch 51/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.1937 - val_loss: 4.0620\n",
            "Epoch 52/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.2339 - val_loss: 4.0191\n",
            "Epoch 53/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.0587 - val_loss: 3.9843\n",
            "Epoch 54/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.0575 - val_loss: 3.9256\n",
            "Epoch 55/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 4.0529 - val_loss: 3.8787\n",
            "Epoch 56/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 4.0252 - val_loss: 3.8976\n",
            "Epoch 57/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.9215 - val_loss: 3.7971\n",
            "Epoch 58/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.9538 - val_loss: 3.7745\n",
            "Epoch 59/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.9290 - val_loss: 3.7328\n",
            "Epoch 60/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.9062 - val_loss: 3.7004\n",
            "Epoch 61/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.8389 - val_loss: 3.6862\n",
            "Epoch 62/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.9544 - val_loss: 3.6423\n",
            "Epoch 63/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.8214 - val_loss: 3.6318\n",
            "Epoch 64/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.8996 - val_loss: 3.5878\n",
            "Epoch 65/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.7070 - val_loss: 3.5682\n",
            "Epoch 66/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.8048 - val_loss: 3.5463\n",
            "Epoch 67/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.6488 - val_loss: 3.5056\n",
            "Epoch 68/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.6319 - val_loss: 3.4916\n",
            "Epoch 69/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.6490 - val_loss: 3.4598\n",
            "Epoch 70/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.6607 - val_loss: 3.4483\n",
            "Epoch 71/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.5660 - val_loss: 3.4321\n",
            "Epoch 72/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.5628 - val_loss: 3.3883\n",
            "Epoch 73/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.5086 - val_loss: 3.3796\n",
            "Epoch 74/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.3909 - val_loss: 3.3957\n",
            "Epoch 75/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.4415 - val_loss: 3.3392\n",
            "Epoch 76/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.3850 - val_loss: 3.3085\n",
            "Epoch 77/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.4132 - val_loss: 3.2892\n",
            "Epoch 78/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.4422 - val_loss: 3.2728\n",
            "Epoch 79/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.3863 - val_loss: 3.2417\n",
            "Epoch 80/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.3255 - val_loss: 3.2041\n",
            "Epoch 81/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.3990 - val_loss: 3.1919\n",
            "Epoch 82/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.2752 - val_loss: 3.1640\n",
            "Epoch 83/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.3427 - val_loss: 3.1369\n",
            "Epoch 84/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.2918 - val_loss: 3.1346\n",
            "Epoch 85/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.3398 - val_loss: 3.1152\n",
            "Epoch 86/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1652 - val_loss: 3.1009\n",
            "Epoch 87/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.2869 - val_loss: 3.0799\n",
            "Epoch 88/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.0857 - val_loss: 3.0509\n",
            "Epoch 89/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.2788 - val_loss: 3.0460\n",
            "Epoch 90/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0890 - val_loss: 3.0349\n",
            "Epoch 91/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1918 - val_loss: 3.0538\n",
            "Epoch 92/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1520 - val_loss: 3.0202\n",
            "Epoch 93/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.1153 - val_loss: 3.1497\n",
            "Epoch 94/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.2391 - val_loss: 3.1038\n",
            "Epoch 95/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0794 - val_loss: 2.9659\n",
            "Epoch 96/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0022 - val_loss: 2.9453\n",
            "Epoch 97/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0866 - val_loss: 2.9536\n",
            "Epoch 98/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1048 - val_loss: 2.9546\n",
            "Epoch 99/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1035 - val_loss: 2.9276\n",
            "Epoch 100/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0769 - val_loss: 2.9526\n",
            "Epoch 101/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1417 - val_loss: 2.9112\n",
            "Epoch 102/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.1782 - val_loss: 2.8942\n",
            "Epoch 103/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0229 - val_loss: 2.8853\n",
            "Epoch 104/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9888 - val_loss: 2.8852\n",
            "Epoch 105/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.0334 - val_loss: 2.8721\n",
            "Epoch 106/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9962 - val_loss: 2.8608\n",
            "Epoch 107/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0120 - val_loss: 2.8373\n",
            "Epoch 108/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9521 - val_loss: 2.8430\n",
            "Epoch 109/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.0593 - val_loss: 2.8172\n",
            "Epoch 110/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0043 - val_loss: 2.9440\n",
            "Epoch 111/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9510 - val_loss: 2.8920\n",
            "Epoch 112/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9694 - val_loss: 2.8426\n",
            "Epoch 113/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9836 - val_loss: 2.7936\n",
            "Epoch 114/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9526 - val_loss: 2.8441\n",
            "Epoch 115/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 3.0119 - val_loss: 2.7825\n",
            "Epoch 116/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.9494 - val_loss: 2.8814\n",
            "Epoch 117/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9291 - val_loss: 2.8640\n",
            "Epoch 118/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 3.0112 - val_loss: 2.8428\n",
            "Epoch 119/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9841 - val_loss: 2.7629\n",
            "Epoch 120/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8717 - val_loss: 2.7703\n",
            "Epoch 121/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9460 - val_loss: 2.7628\n",
            "Epoch 122/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9374 - val_loss: 2.7396\n",
            "Epoch 123/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8548 - val_loss: 2.7785\n",
            "Epoch 124/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9370 - val_loss: 2.7226\n",
            "Epoch 125/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7839 - val_loss: 2.7767\n",
            "Epoch 126/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.9131 - val_loss: 2.8684\n",
            "Epoch 127/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8380 - val_loss: 2.7789\n",
            "Epoch 128/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8356 - val_loss: 2.7593\n",
            "Epoch 129/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8840 - val_loss: 2.7228\n",
            "Epoch 130/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8889 - val_loss: 2.8650\n",
            "Epoch 131/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8981 - val_loss: 2.7283\n",
            "Epoch 132/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9464 - val_loss: 2.7454\n",
            "Epoch 133/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8249 - val_loss: 2.7039\n",
            "Epoch 134/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8599 - val_loss: 2.7452\n",
            "Epoch 135/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8972 - val_loss: 2.7516\n",
            "Epoch 136/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8243 - val_loss: 2.7265\n",
            "Epoch 137/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7381 - val_loss: 2.8211\n",
            "Epoch 138/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7865 - val_loss: 2.7841\n",
            "Epoch 139/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.6542 - val_loss: 2.8193\n",
            "Epoch 140/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8739 - val_loss: 2.6765\n",
            "Epoch 141/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8693 - val_loss: 2.6920\n",
            "Epoch 142/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8602 - val_loss: 2.7122\n",
            "Epoch 143/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8332 - val_loss: 2.7556\n",
            "Epoch 144/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7757 - val_loss: 2.7484\n",
            "Epoch 145/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8671 - val_loss: 2.8130\n",
            "Epoch 146/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8458 - val_loss: 2.7120\n",
            "Epoch 147/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8228 - val_loss: 2.7650\n",
            "Epoch 148/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9407 - val_loss: 2.6838\n",
            "Epoch 149/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7386 - val_loss: 2.6927\n",
            "Epoch 150/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8509 - val_loss: 2.7294\n",
            "Epoch 151/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9111 - val_loss: 2.7031\n",
            "Epoch 152/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7517 - val_loss: 2.6918\n",
            "Epoch 153/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8272 - val_loss: 2.7566\n",
            "Epoch 154/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8572 - val_loss: 2.7095\n",
            "Epoch 155/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.9396 - val_loss: 2.7244\n",
            "Epoch 156/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8612 - val_loss: 2.7880\n",
            "Epoch 157/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7871 - val_loss: 2.6926\n",
            "Epoch 158/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7893 - val_loss: 2.7082\n",
            "Epoch 159/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7574 - val_loss: 2.6661\n",
            "Epoch 160/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7833 - val_loss: 2.7001\n",
            "Epoch 161/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7172 - val_loss: 2.7028\n",
            "Epoch 162/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8290 - val_loss: 2.6680\n",
            "Epoch 163/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8462 - val_loss: 2.7237\n",
            "Epoch 164/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7966 - val_loss: 2.7068\n",
            "Epoch 165/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8676 - val_loss: 2.7115\n",
            "Epoch 166/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7685 - val_loss: 2.6821\n",
            "Epoch 167/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8118 - val_loss: 2.6630\n",
            "Epoch 168/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.9088 - val_loss: 2.7561\n",
            "Epoch 169/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7755 - val_loss: 2.6809\n",
            "Epoch 170/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8381 - val_loss: 2.6987\n",
            "Epoch 171/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8424 - val_loss: 2.6940\n",
            "Epoch 172/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8342 - val_loss: 2.7964\n",
            "Epoch 173/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8055 - val_loss: 2.6678\n",
            "Epoch 174/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.6901 - val_loss: 2.7172\n",
            "Epoch 175/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7880 - val_loss: 2.6824\n",
            "Epoch 176/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7634 - val_loss: 2.7337\n",
            "Epoch 177/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7929 - val_loss: 2.6561\n",
            "Epoch 178/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8334 - val_loss: 2.6694\n",
            "Epoch 179/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7939 - val_loss: 2.7299\n",
            "Epoch 180/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7753 - val_loss: 2.6803\n",
            "Epoch 181/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8011 - val_loss: 2.6909\n",
            "Epoch 182/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7916 - val_loss: 2.7467\n",
            "Epoch 183/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7849 - val_loss: 2.7194\n",
            "Epoch 184/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7922 - val_loss: 2.6862\n",
            "Epoch 185/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7212 - val_loss: 2.6673\n",
            "Epoch 186/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7526 - val_loss: 2.6866\n",
            "Epoch 187/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8457 - val_loss: 2.6872\n",
            "Epoch 188/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8180 - val_loss: 2.6695\n",
            "Epoch 189/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7735 - val_loss: 2.6524\n",
            "Epoch 190/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8262 - val_loss: 2.6890\n",
            "Epoch 191/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8120 - val_loss: 2.7540\n",
            "Epoch 192/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7839 - val_loss: 2.7013\n",
            "Epoch 193/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8457 - val_loss: 2.6652\n",
            "Epoch 194/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7462 - val_loss: 2.6866\n",
            "Epoch 195/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7165 - val_loss: 2.6683\n",
            "Epoch 196/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8367 - val_loss: 2.6654\n",
            "Epoch 197/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7971 - val_loss: 2.7374\n",
            "Epoch 198/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7819 - val_loss: 2.6537\n",
            "Epoch 199/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7852 - val_loss: 2.6536\n",
            "Epoch 200/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7518 - val_loss: 2.6890\n",
            "Epoch 201/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7862 - val_loss: 2.6908\n",
            "Epoch 202/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8579 - val_loss: 2.6733\n",
            "Epoch 203/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7551 - val_loss: 2.7751\n",
            "Epoch 204/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7915 - val_loss: 2.6611\n",
            "Epoch 205/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7306 - val_loss: 2.7288\n",
            "Epoch 206/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7180 - val_loss: 2.7366\n",
            "Epoch 207/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8055 - val_loss: 2.6909\n",
            "Epoch 208/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8690 - val_loss: 2.7285\n",
            "Epoch 209/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8658 - val_loss: 2.6836\n",
            "Epoch 210/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7271 - val_loss: 2.6695\n",
            "Epoch 211/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7679 - val_loss: 2.6877\n",
            "Epoch 212/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7724 - val_loss: 2.6968\n",
            "Epoch 213/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7668 - val_loss: 2.6605\n",
            "Epoch 214/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7623 - val_loss: 2.7447\n",
            "Epoch 215/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7700 - val_loss: 2.6579\n",
            "Epoch 216/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7989 - val_loss: 2.7007\n",
            "Epoch 217/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.6424 - val_loss: 2.7084\n",
            "Epoch 218/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7083 - val_loss: 2.7884\n",
            "Epoch 219/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7420 - val_loss: 2.6494\n",
            "Epoch 220/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7136 - val_loss: 2.6817\n",
            "Epoch 221/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7953 - val_loss: 2.7043\n",
            "Epoch 222/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7631 - val_loss: 2.6468\n",
            "Epoch 223/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7644 - val_loss: 2.7175\n",
            "Epoch 224/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7625 - val_loss: 2.7189\n",
            "Epoch 225/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.9081 - val_loss: 2.7586\n",
            "Epoch 226/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8638 - val_loss: 2.6536\n",
            "Epoch 227/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7429 - val_loss: 2.6523\n",
            "Epoch 228/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7462 - val_loss: 2.6744\n",
            "Epoch 229/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7970 - val_loss: 2.6569\n",
            "Epoch 230/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7366 - val_loss: 2.6529\n",
            "Epoch 231/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7609 - val_loss: 2.6904\n",
            "Epoch 232/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7339 - val_loss: 2.6777\n",
            "Epoch 233/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7787 - val_loss: 2.7158\n",
            "Epoch 234/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8193 - val_loss: 2.7387\n",
            "Epoch 235/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8580 - val_loss: 2.6718\n",
            "Epoch 236/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8566 - val_loss: 2.6853\n",
            "Epoch 237/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7773 - val_loss: 2.6476\n",
            "Epoch 238/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7046 - val_loss: 2.7153\n",
            "Epoch 239/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8077 - val_loss: 2.6610\n",
            "Epoch 240/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7579 - val_loss: 2.6625\n",
            "Epoch 241/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.6824 - val_loss: 2.6683\n",
            "Epoch 242/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8510 - val_loss: 2.8045\n",
            "Epoch 243/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7682 - val_loss: 2.6726\n",
            "Epoch 244/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7876 - val_loss: 2.7322\n",
            "Epoch 245/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8378 - val_loss: 2.6843\n",
            "Epoch 246/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7934 - val_loss: 2.6504\n",
            "Epoch 247/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7293 - val_loss: 2.7527\n",
            "Epoch 248/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7571 - val_loss: 2.6827\n",
            "Epoch 249/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8806 - val_loss: 2.6496\n",
            "Epoch 250/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7800 - val_loss: 2.6593\n",
            "Epoch 251/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8001 - val_loss: 2.6587\n",
            "Epoch 252/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.5818 - val_loss: 2.6587\n",
            "Epoch 253/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8548 - val_loss: 2.6734\n",
            "Epoch 254/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.6964 - val_loss: 2.6581\n",
            "Epoch 255/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7223 - val_loss: 2.6666\n",
            "Epoch 256/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7757 - val_loss: 2.6690\n",
            "Epoch 257/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7217 - val_loss: 2.6844\n",
            "Epoch 258/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7581 - val_loss: 2.6725\n",
            "Epoch 259/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7517 - val_loss: 2.6786\n",
            "Epoch 260/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.6739 - val_loss: 2.6521\n",
            "Epoch 261/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.6935 - val_loss: 2.7706\n",
            "Epoch 262/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7798 - val_loss: 2.6857\n",
            "Epoch 263/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7717 - val_loss: 2.6555\n",
            "Epoch 264/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8164 - val_loss: 2.6883\n",
            "Epoch 265/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8315 - val_loss: 2.6649\n",
            "Epoch 266/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8809 - val_loss: 2.7283\n",
            "Epoch 267/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8244 - val_loss: 2.8455\n",
            "Epoch 268/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7821 - val_loss: 2.7532\n",
            "Epoch 269/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8799 - val_loss: 2.7836\n",
            "Epoch 270/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7654 - val_loss: 2.6571\n",
            "Epoch 271/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7490 - val_loss: 2.6643\n",
            "Epoch 272/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8697 - val_loss: 2.7264\n",
            "Epoch 273/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7838 - val_loss: 2.6581\n",
            "Epoch 274/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8284 - val_loss: 2.6818\n",
            "Epoch 275/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7758 - val_loss: 2.6753\n",
            "Epoch 276/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7656 - val_loss: 2.6491\n",
            "Epoch 277/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7427 - val_loss: 2.6825\n",
            "Epoch 278/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7409 - val_loss: 2.6779\n",
            "Epoch 279/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7582 - val_loss: 2.6533\n",
            "Epoch 280/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7325 - val_loss: 2.7627\n",
            "Epoch 281/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.6862 - val_loss: 2.6494\n",
            "Epoch 282/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7208 - val_loss: 2.6458\n",
            "Epoch 283/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7877 - val_loss: 2.6687\n",
            "Epoch 284/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7394 - val_loss: 2.6581\n",
            "Epoch 285/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.6921 - val_loss: 2.6594\n",
            "Epoch 286/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7793 - val_loss: 2.6894\n",
            "Epoch 287/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.8280 - val_loss: 2.7032\n",
            "Epoch 288/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8416 - val_loss: 2.6514\n",
            "Epoch 289/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7987 - val_loss: 2.6576\n",
            "Epoch 290/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7369 - val_loss: 2.7690\n",
            "Epoch 291/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7538 - val_loss: 2.7226\n",
            "Epoch 292/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.6912 - val_loss: 2.6477\n",
            "Epoch 293/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7151 - val_loss: 2.6592\n",
            "Epoch 294/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7186 - val_loss: 2.6936\n",
            "Epoch 295/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.8517 - val_loss: 2.6522\n",
            "Epoch 296/300\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 2.7514 - val_loss: 2.6443\n",
            "Epoch 297/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7921 - val_loss: 2.6459\n",
            "Epoch 298/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7350 - val_loss: 2.7483\n",
            "Epoch 299/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7833 - val_loss: 2.7270\n",
            "Epoch 300/300\n",
            "51/51 [==============================] - 0s 2ms/step - loss: 2.7005 - val_loss: 2.6509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5a4024d2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zox504AjSX5"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ugJWuGjXgv"
      },
      "source": [
        "lossData = pd.DataFrame(model.history.history) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oZBlC46Qmgnj",
        "outputId": "0d303cb5-bdcb-405a-9d1e-a1bf71e9db8d"
      },
      "source": [
        "lossData.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5a3f1ea350>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNCT7y-wozVV"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "M71ZyAJko0tf",
        "outputId": "c0d8d4b9-7b36-4704-bd75-aae1849b4479"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "pr = model.predict(x_test)\n",
        "pr = np.rint(pr) \n",
        "mean_absolute_error(y_test,pr)\n",
        "plt.scatter(y_test,pr)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df2xU55kv8O9jG/M7EFPjBAdj4yCz2VoJjbcG+TYKzbJuYZVaUZOGDRJaZck/1W5TVpZsxVe9VyLCVVbZ3T+iSmmjq0hL2ASUOpGMQi1wrla5jVVTJ3J+wBIIP+IGcPnZgkmMee4fc8Z4Zs77nuHMnJk553w/UmTmfWfGZw7O48P7nOd5RVVBREThU1bsAyAiIn8YwImIQooBnIgopBjAiYhCigGciCikKgr5zb7xjW9ofX19Ib8lEVHoHTp06I+qWp0+XtAAXl9fj+Hh4UJ+SyKi0BORk27jXEIhIgopBnAiopBiACciCikGcCKikGIAJyIKqYLehUJEFCd9I2N4Yf8R/OHSBJYtnovO9iZ0rKnN2/szgBMRBaBvZAzdb45iYnIKADB2aQLdb44CQN6COJdQiIgC8ML+I9PBO2licgov7D+St+/BAE5EFIA/XJq4rXE/GMCJiAKwbPHc2xr3g2vgREQebMlI01xne1PKGjgAzJ1Vjs72prwdFwM4EZGFLRkJwDNRGeRdKFLIPTFbWlqUzayIKEzaeg9izGXdutZZCjHNvdf13bwdg4gcUtWW9HFegRMRWfhJRuYzUWnDJCYRkYUtGVmIRKUNr8CJiAD09I1i99BpTKmiXASbW5djR0czOtub0Ln3Q0xO3VpunlUu08nIoBOVNgzgRBR7PX2j+I/3T00/nlKdftyyogpITxU6jwuRqLRhEpOIYq+xex+mXGJhuQjuWjSnIIlKG1MSk2vgRBR7bsE7OV6Iikq/uIRCRJHip+imXOS2r8ALlai0YQAnosjwW3SzduWdeO/YhYz3W7vyTjRUL0hZH09avzpjk/iCYwAnosjw6gB4u90BT5yfwInz7kslg4fHczza3DGAE1Fk5LvophSKdWyYxCSiyPBbdFPKxTo2WQVwEfmJiHwkIh+LyLPOWJWIDIjIUefrncEeKhFRQt/IGNp6D6Khqx9tvQfRNzIGAOhsb8KsMkl57qyyRNFNZ3sTJO19xHmN1+vmzipPmStksY6NZwAXkW8C2Abg2wDuB/C3InIvgC4AB1R1FYADzmMiokAlE5VjlyaguJWMTAZx1ygNYM/wKdd6nD3Dp6yv61hTi52PNaN28VwIEvd/73ysuWDFOjaehTwi8jiA76nq087j/wngKwBPA3hYVb8UkbsBvKuq1l9JLOQholz57Q7oNu41X8hiHZtcCnk+AvAdEVkiIvMAbASwHECNqn7pPOcMgBrDN35GRIZFZHh8vPhZWyIKN1ui0m/RTSkX69h4BnBV/RTAzwH8BsA7AD4AMJX2HEVmt4Dk3Muq2qKqLdXVxb9vkojCLYiEYyknKm2ySmKq6iuq+qCqPgTgIoD/BnDWWTqB8/VccIdJRJTglYwsT0tGljvJyLbGKtf3a2usKulEpU22d6Esdb7WAXgMwGsA3gaw1XnKVgBvBXGAREQzvTR41DUZ+dLgUQyfvICpm6mzUzcVwycv4PGWOtf3e7ylrqQTlTZZdSMUkf8CsATAJIDtqnpARJYAeANAHYCTAJ5Q1cxa1BmYxCSiXNV39Rvn/PQ0KZVEpU1OW6qp6ndcxs4DeCQPx0ZElBdh7SroF0vpiahobJ0DN7z4Lo6euzr93FVL52Ng+8PW9wtrV0G/GMCJqChsnQNfGjyaErwB4Oi5q9jw4ruoEOCGy4V2hQCtlq6Cye+Rrn4JAzgR0W2xdQ40Fd2kB/WZbiiMnQNPnJ/AmcvXXefeP34xyyMuPQzgRFQUQaxJ297TdLuGad08DNiNkIiKIojiGdt7lkv63eMJpvEwYAAnokDZOgeaCnJWLZ3v+l6rls63ztm6Cm5uXe76OtN4GHAJhYgC45WoNBXknDWsV5+9fB2Prql1XQtvXbkk8QdDV8EdHc0AgN1DpzGlinIRbG5dPj0eRlkV8uQLC3mI4sXWOdDWHdAmqsU6Nrl0IyQi8iWIRGXcinVsGMCJKDBBJCptyciwdhX0iwGciHLW0zeKxu59qO/qR2P3PvT0Jda5/SYq75hd7jp3x+xyazIyrF0F/WISk4hy0tM3iv94/9T04ynV6cdDx88bE5VXJiZd3+/KxCSa71nkWlHZfM8ifD7+Z9fXfT7+5+mEpKk8P2qYxCSinDR27zMmFQtdJHOid1NBv1+hMIlJRIGwJRUpWAzgRJSTKFY4hgXXwIlCyNaG1TZn09M3ai1yube7P6ULYIUAn+3chM2ty1PWwJM2ty7H0PHzrkU3q5bOx5WJSZz909cZczULK3Hv0gWua+DJbdFsc16fI0oYwIlCxlbdCMA4ZwvitkTkjo7mjOANJLr/3dvdj4oy9yvtvb87jRs33ZdRPh+/iobq+a4B/I65s9BQ7R7AG6oXAHAP4A3VCzw/R9QwiUkUMrbqRsC957VXJaItEXls50brNmZBsFVbAu7r615zx3ZuzPNRFk5OW6oRUenwU23oVYlYaolIP8fjdy7MmMQkChlbtaHfSsRSS0TajsfvXBQxgBOFzPrV1cZx0/ZgXtuGiWG7A9N4PphCqsDc4nVz63Lfc1HEJRSikBk8PG4c97ttmNsek7bxfDC9tSK71q9+56KEAZwoZOKybdiOjmZj4PU7FzVcQiEKmbhtG0ZmvAInCpnO9iZsf+MDzLzFukwS48MnLxiLagC43g54oncT7phdjitfTWXMmboCZmtOueD6VObV/5xywaJ5s4yFPJQdXoEThczwyQtIr4+5qYnxlhVVGf9TlwFoWVFlvJe7vqvfNXgDMI5na9G8Wcbx7o33uc6ZxikTAzhRyOweOm0cf2H/EdxMG7+JRHvVYnC7wk6Om46pWMcaRgzgRCETlS3FwnSspYoBnChkorKlWJiOtVQxgBMFrG9kDG29B9HQ1Y+23oPoGxnL6XVeW4q5KdaWYqaEZM3CythtfxYE3oVCFCBb50Bbd0Db62xbiu39nfv6eNfeD31/Bi81CyuNd5Ncvua+bdrla5PTnz8u258FgQGcKEAv7D8yHYSTJian8ML+I9ZAZXudW7dBwL3FapLbrXz5YktUmiSPp2NNLQN2DriEQhQgv4k6JvgoG7wCJ8oD0y44yxbPdb1iTibq/LzOdAUeRn53D6IEBnCiHNnWqzvbm1LmgFuJOtvrzl52D9Km8WKqEPemV6bxJL/5AbqFSyhEOfJa5975WDNqF8+FILEzzs7HmtGxptb6umJ0B/TL77HaPj9lh1fgRDnyWq82Jerivs4d98+fD7wCJ8qR34KUuBeyxP3z50NWAVxEfioiH4vIRyKyW0TmiEiDiAyJyGci8rqIsIUYxVJnexPSN2ZPdgf0ep1pfE65e7XlnHKx7mQTlArDm1cI0NZY5TrX1lhlnfMq5PFbABUnngFcRGoB/BOAFlX9JoByAE8C+DmAf1XVewFcBPB0kAdKVKps3QFtdu77xDhuum/7+pRad7LxyxagAWDJAvfrsyULKtFQvcB1rqF6AXZtW5cRxNsaq7Br2zprfiCZ4BxzNqlIJjgZxFNluwZeAWCuiEwCmAfgSwDfBfB3zvyrAP4XgF/k+wCJSp2tO6BtZxg/BTBB8UpE2o7V6/Pv2rbO+H1N+QG/BVBx43kFrqpjAP4FwCkkAvdlAIcAXFLVG87TvgDgelZF5BkRGRaR4fFx9738iMLM1h0wDoL4/ExwZiebJZQ7AfwAQAOAZQDmA/hett9AVV9W1RZVbamudt9NmyjM4r6NWRCfnwnO7GSzhPLXAD5X1XEAEJE3AbQBWCwiFc5V+D0AuDhFoeenMnBz63LrNmYNXf0p69MC4PPeTdYmUIVeRrEV49iOqWZhJTb85V3Wz++HrQCKbsnmLpRTANaKyDwREQCPAPgEwCCAHzrP2QrgrWAOkagwgkicpQdvIJFsbOjqL6k1cFOvq+T40HMbMlrD1iysxNBzG6zdEf2yJTjpFs8rcFUdEpG9AH4P4AaAEQAvA+gH8J8issMZeyXIAyUKmt/EmS2JF8QdI0HI5jiHntvg+hxTF0Rbd8RssFOht6zuQlHVnwH4WdrwcQDfzvsRERWJ38RZ3JOYVDysxCRy+E2cxT2JScXDXigUOz19o9g9dBpTqigXwebW5djR0YzO9iZsf/2DlF3dy3CrYrL1+YGU9enkGrAtibnr/VOuyxOC0lpGMR3PzF9BpgRvW2OV63KJqQqT8ocBnGKlp280JdhOqaY8vpn2/JtIVFTu3PdJRnLx7J++RuvzA8bvNfDxmZJaA/dzJ8lTa+sA2Fu/Pt5Sh/937ELGnTaPt9Tl/TNQKtECrtO1tLTo8PBwwb4fUbrG7n2ua9PJ5Q7TXNTXs02fsVwEx3ZuRFvvQdeNJGqd5SXT3Htd383/wcaQiBxS1Zb0cV6BU6z4SThGPXgD3ufFT4KXVZPBYwCnSDKt19quNAFegbuNA+at3JZZrsBZNRk83oVCkWMryFlZPc/1NSur51nnom7tyjut4+tXu7fBWL+62rMtLAWHV+AUObaCnDOXr7u+5vj4NeP72eai4sR59+WO5PjgYfdGdIOHx6c7LnJz4sJjAKfIsa3XmhZC4r4G7rXG7XfbOAoWl1AocmwFObaimzgX5HgVMbE7YGliAKfABbU1lul9bWuypg55m1uXW+fSGzklmcZL0R2zy43jne1NmJW2L9ysMplex+Y6d2niEgoFylYAkss/ubN5X7c12ZcGj7q+39Dx8/js3FXXOVM1JVCczoE2q5bOx1GXz7Fq6Xy0rlziWqzzaPLvIf0fGjMe284pFQ8LeShQtgKQXIo8/L5vfVe/7+8ZdrZbBe9aNIfFOCXMVMjDJRQKVFBbY3HLrdtnK9bh+QwnBnAKVFDJLybVbp8tScvzGU4M4BQor+RXT98oGrv3ob6rH43d+9DTN5r1+9rGTe+7aul819etWjo/Ywk4KUz3oNg+ny1JyyRlODGJSYGyJb9snQGTxSEmpmTkS4NHMXzygvF9Px93T1R+Pn61pDoH2tj2r1y6cLZrEnPpwtnT59StlW4Sk5ThwiQmFY2tM+CxnRutr7UlI23JujgU5Zic6N1U7EMgn5jEpJIT1FZk3OKM4oJLKFQ0Xh3wTB0Fc3lfBnGKEl6BU9HYkmq2joJe4nwFbktiUvQwgFPR7Ohoxpa1ddNX3OUi2LK2Djs6mq0dBcns2tfpm8LZxyncuIRCRbWjo9n1jhMWlvjD8xYvvAKnksTCEn943uKFV+CUNb9JRZsNL76bct/yqqXzMbD9YXS2N+HZ1z/IeH6ysOSO2eW48tVUxrxpPGxsn29uZblxd/nO9qaUJl8AC3KijFfglJVckoom6cEbAI6eu4oNL76Ln7oEbwDT46YgHabgbUs4Pmr4xfjomlp0b7zPda57433oWFOLnY81o3bxXAgSzah2PtbMgpyI4hU4ZcWWVPQbHNwqBm3jQOlVRebC9vlN27jtHjpt3N4s+XfB3XHig1fglBUmxwqLnQMpGwzglBUmxwqLnQMpG1xCoax0tjehc8+HmLx568pw5pZbT/3yt3jv2IXpubbGKuzatg4A0Pr8QErSrWZhJYae22DdPeazc+7NpcLUGdCLn91zNrcuR8uKKiYqCQADON0Ow5Zb6cEbAN47dgFP/fK3+OzcnzPumDj7p6/R+vyA8dtcmZgMTWdAL1vW1rkG4i1r69Cyosr1Tpsfr181vYbNzoFkw26ElBXbFmZu40E60bspNFujcRszygd2I6ScMHHmD5ORFCQuoVAKU7HOMsOVtmmcEvxcgSeTkUEUTlG08AqcptmKdeqXuN/hUL9kLu6YXe46d8fs8khsU5aLldXzjOPrV1e7zq1fXR1I4RRFD6/AaZqtWOfM5euur3n/+EXjMoGtKjJsyUi/TAU5x8evGTsEDh4ex+Dh8bwXTlH0MIDTNNuarCngxqHHdi7yvQbO9XGaiUsoNM1WIGIrLCEzvwU5LNahbHgGcBFpEpEPZvx3RUSeFZEqERkQkaPO1zsLccCUnb6RMbT1HkRDVz/aeg9mtXZqKgTpbG+y7p7T1ljlOtfWWBWLHWJsOQDbeetsb8KsstQAnyyO6mxvwtxZqe/LYh1K5xnAVfWIqj6gqg8AeBDANQC/BtAF4ICqrgJwwHlMJcBvAmzPcGbBiW086dCJi8ZxPw2rSlGF4R8aFQI037PIda75nkXWXYcAGIuj2FWQsnFbhTwi8jcAfqaqbSJyBMDDqvqliNwN4F1VtV4esJCnMGxFN7YCEVtxTCltFBymQp4TvZuMc37/nih+8lXI8ySA3c6fa1T1S+fPZwDUGL7xMyIyLCLD4+PubTApv4IoEInzRsFBYSEP5SrrAC4ilQAeBbAnfU4Tl/Gu/yer6suq2qKqLdXV7ve9Un4FkQBjEjP/mKikXN3OFfj3AfxeVc86j886Sydwvp7L98GRP7bkmI0tGWlLxs0pdw/ipvEwsq2B286bDROVlKvbCeCbcWv5BADeBrDV+fNWAG/l66AoDwzJMZuG6gXG8YGPz7jODXx8Bten3JdRTOOlyhakP9u5KWM+Ob5r27qMYD2zna4JE5WUq6ySmCIyH8ApACtV9bIztgTAGwDqAJwE8ISqXjC/C5OYheI3OdbYva9kEpU2xUhi2pKRREEzJTGzqsRU1asAlqSNnQfwSH4Oj/LJb3KMiUqicGElZgT5TY4xUUkULuyFUuL8tBTtbG/CP+/5EFMztj8rn5HE3PDiuymFNKuWzsfA9oexuXW5cRuvgY/PZOysAyS2R3MbD6MKAW64/GMjufbd0zdq3SGHqNAYwEtYsqIy2ZUuWVEJwBrEh09eSAneADB1UzF88gJeGjyaUQV59NxVbHjxXXxmqI7c9f4pYzOrsAVvP/tQPtlah56+0ZS5KdXpxwziVCxcQilhtvauNruHThvHbaXtUdmH0sb2+W3nzTZHVCy8Ai9hTEYWlp/zxnNKxcQr8BLGZGRh2c4bzymVIgbwEua3Um/tSvfOvmtX3mktVokDW3tb23mzVaISFQsDeAnzW6l34rz7EsuJ8xOud1kA7ndfRNHA9oczgnjyLhzbefNsC0tUBFwDL3Eda2pvu7SaXe7sBrY/7Drudd52dDQzYFNJ4RV4BLHLnT88bxQ2DOARZNsaLSpbnNm2MfPbHZHdASlsGMAj6KXBo8bxsGxx5hWEaxbNcZ2vWTQHvT+833XONJ7E7oAUNlwDj6CwBGkbrxa1ts9oKnR6Yf8Rz2DsJ+dAVCy8AqfIYRKX4oIBnCKHyUiKCy6hFIifroJer3vql7/Fe8du7aGR3AXG1rApLMsoc8rFdRkluQZu+4w/Xr8qpQkYwGQkRRMDeAH47Spoe92e4VMpwRsA3jt2AU/98rc4e/m66/uZxovF1Iq2ZmElNvzlXa6dAX/4V4nKx4HtDxvb4ib5+YVJFCZZbamWL3HdUs3vFme217mNR4lpG7dyERzbubEIR0RUPKYt1bgGXgB+k2pxTsaxoyKRNy6h5JFpvXqZ4Yo5mVTz87o4X4ETUQKvwPMkuV49dmkCilvr1X0jY9YKP9vr1q+udv1e61dXo2ZhpeucabwU2aopbZ0BiSiBV+B5Yts9J7nO7XaV3dZ78LZ33Rk8PI4//nnSdc40Xiy2K+mFcytx5avMf0ksnFtp7QxIRAkM4HnitV5tqvDzs879B+dq3U2prRHb1rL9fnYiSuASSp74LR6xvc42F5YdYmzH6fezE1ECA3ieeHWy6xsZQ1vvQTR09aOt9yD6RsamX5f+l1DmjHe2N2FWWlOnWeWCzvamktohxtZ4ynactnOWTWdA0zkligsuoeRJcnnEbZ3bVpAzfPICbqa9101nvGVFVeaW8M7jvb9z3w3dNJ6rCnHftadCgMqKMlyfmsqYq6woQ8uKKrz2/qmUz1gGoGVFlfWcJZnm/BZHEUUJC3kKwFaQc+bydWOS765Fc0JfyGM6Vq8iJi9+i6OIwshUyMMr8AKwJetsycgoFPIE9RmicG6IcsU18ALwm4yMQiIvqM8QhXNDlCsG8ALobG/CrLK0ZGSZdzKys70J6eFdnPfzu22YXxWGt60Qe0GO7bPngtufETGAF45bJPawZ/iUaw5zz/Apzx1rTGwVnFvW1rnObVlbhyUL3F+3ZEElHjUkDafHfXx2L9z+jIhJzILwm8QsdFGOrWrSdiy219kSsUw2EmWHScwi8pvELDS/HQDzXW1JRNnhEkoBhKWi0u+xRD0RS1SqGMDzqKdvFI3d+1Df1Y/G7n3o6UsUlvitqGxrrHKdM41nw7YGbjsWv69jspEoOFxCyZOevtGULcCmVKcf2yoq3zaUf789MoYrX2VWNwLI2EotnSDz2yXHJ752f0/TeNLQcxvQ+vxAyhZoNQsrMfTchunHu4dOY0oV5ZIood/R0Tw9x+3NiPKPScw8aezeF/qKSm5jRlSauKVawKKQyOM2ZkThklUAF5HFIrJXRA6LyKcisk5EqkRkQESOOl9jvVVKFBJ5pZRQJSJv2V6B/zuAd1R1NYD7AXwKoAvAAVVdBeCA8zi2bIm8Gy6d+gAYx4NkCsUC+2cgotLjGcBFZBGAhwC8AgCq+rWqXgLwAwCvOk97FUBHUAcZBjs6mrFlbd301Wq5CLasrcOOjuaUxN9MpvFc2a6kTYshCvtnIKLS45nEFJEHALwM4BMkrr4PAfgJgDFVXew8RwBcTD5Oe/0zAJ4BgLq6ugdPnjyZ1w8QBvVd/cU+hKyc6N1U7EMgIhe5JDErAHwLwC9UdQ2Aq0hbLtHEbwHX3wSq+rKqtqhqS3W1+y7rlF9cyyaKh2wC+BcAvlDVIefxXiQC+lkRuRsAnK/ngjnE0uG1hZdpftXS+a7vZxrPht/CGq/iIG5TRhQengFcVc8AOC0iydK5R5BYTnkbwFZnbCuAtwI5whKR3MJrzOlfktzCKxngbPOnz19zfU/TeJKtO2D3xvtc57o33mddy961bV1GEG9rrMKubes8PyMRlZasCnmcdfBfAagEcBzA3yMR/N8AUAfgJIAnVNVaIhjmQh6vLbxs836LdQrd5Y/blBGVppy6EarqBwAyXozE1XgseBXjBFGsU+jioLAUHBFRAisxs+RVjBNEsU6hi4PCUnBERAkM4Fny6qpn6q6Xy/ZnXl3+TB0O/WLnQKJwYQDPktcWXl17P3R9XdfeD63bn/3bjx5wnfu3Hz2AlhVVGX9BZXC6GwLGDod+cZsyonBhN8I88VusY0py1jrLFn7mmHAkihZuqVai/CQO/c4RUbQwgKfp6Rs1bkxgm/NrmeEKfJnlKjubOSKKPgbwGWy76gAwzuUSxDvbm9D95igmJm91JpyZOPQ7R0TRxwA+w+6h07c1npzzCuAneje5rpHPbB5l23LM7xwRRRsD+Ax+dqTJdrcaW6e/jjW1xsDrd46Ioo+3Ec5gK5xhhz8iKjUM4DPYCme8dqvx6vJHRJRvDOAzeBbOWNi6/BERBYGFPDPYuvGduXzd2Bnw2M6NhTg8IoopFvJkwVZUY/o1l20Sk4go37iEMoOtGx+TmERUamIZwHv6RtHYvQ/1Xf1o7N6Hnr5RALB2+PNKYhIRFVrsAniy2jK59JGsqEwGcVOHv5YVVShLu9guk+wSnEREQYjdGrit2nLw8Dgmb6ZG8Mmbihf2HwEApE3hpiYqIVlMQ0TFELsAnu9tytj9j4iKJXZLKH63KeN2Y0RUaiIbwPtGxtDWexANXf1o6z2IvpExAN7blJm2FON2Y0RUaiK5hNI3MpbSanXs0gS630wkKVtWVOG1oVMp69nJZGRyLZvd/4goDCJZiWmrqAS4FRkRhUusKjGZjCSiOAh1AO8bGXNd0shlmzIiorAIbRIzuc495vQpSa5z942MYf3qatfXrF9dzWQkEUVGaK/AX9h/JGU/SACYmJyaLrpxM3h4fHr7MyYjiSjsQhvAc1nn5lZkRBQFoV1CYdENEcVdyQdwU0EOi26IKO5KegnFVpDDohsiiruSLuSxFeSw6IaI4sJUyFPSSyh+EpVERHFR0gGcyUgiIrOSDuBMRhIRmZV0EjObRCURUVyVdAAHWHRDRGRS0ksoRERkltUVuIicAPAnAFMAbqhqi4hUAXgdQD2AEwCeUNWLwRwmERGlu50r8PWq+sCMexG7ABxQ1VUADjiPiYioQHJZQvkBgFedP78KoCP3wyEiomxlG8AVwG9E5JCIPOOM1ajql86fzwCocXuhiDwjIsMiMjw+Pp7j4RIRUVJWpfQiUquqYyKyFMAAgH8E8LaqLp7xnIuqeqfH+4wDOGl5yjcA/DGrI48fnhsznht3PC9mYTs3K1Q1Y6earJKYqjrmfD0nIr8G8G0AZ0XkblX9UkTuBnAui/dx3yrHISLDbvX+xHNjw3PjjufFLCrnxnMJRUTmi8jC5J8B/A2AjwC8DWCr87StAN4K6iCJiChTNlfgNQB+LSLJ57+mqu+IyO8AvCEiTyOxLPJEcIdJRETpPAO4qh4HcL/L+HkAj+T5eF7O8/tFCc+NGc+NO54Xs0icm4L2AyciovxhKT0RUUgxgBMRhVTRAriInBCRURH5QESGnbEqERkQkaPOV+t95VElIotFZK+IHBaRT0VkHc8NICJNzs9L8r8rIvIsz02CiPxURD4WkY9EZLeIzBGRBhEZEpHPROR1Eaks9nEWmoj8xDknH4vIs85YJH5min0Fzv4q7v4dwDuquhqJBPKn4LmBqh5xfl4eAPAggGsAfg2eG4hILYB/AtCiqt8EUA7gSQA/B/CvqnovgIsAni7eURaeiHwTwDYkalfuB/C3InIvIvIzU+wAni72/VVEZBGAhwC8AgCq+rWqXgLPTbpHABxT1ZPguUmqADBXRCoAzAPwJYDvAtjrzMfx3PwFgCFVvaaqNwD8XwCPISI/M8UM4L77q0RcA4BxAP9HREZE5FdOARXPTaonAex2/hz7c+NUS/8LgFNIBO7LAA4BuMfyiOcAAAG4SURBVOQELgD4AkDcdkf5CMB3RGSJiMwDsBHAckTkZ6aYAfx/qOq3AHwfwI9F5KGZk5q4vzGO9zhWAPgWgF+o6hoAV5H2z7sYnxsAgLOO+yiAPelzcT03zhruD5C4AFgGYD6A7xX1oEqAqn6KxDLSbwC8A+ADJPY1mPmc0P7MFC2Az+yvgsQ65nR/FQDItr9KBH0B4AtVHXIe70UioPPc3PJ9AL9X1bPOY54b4K8BfK6q46o6CeBNAG0AFjtLKgBwD4CxYh1gsajqK6r6oKo+hEQe4L8RkZ+ZogRw9lcxU9UzAE6LSJMz9AiAT8BzM9Nm3Fo+AXhugMTSyVoRmSeJvhfJn5tBAD90nhPLc+N0UYWI1CGx/v0aIvIzU5RKTBFZicRVN3Crv8rzIrIEwBsA6uD0V1HVCwU/wCITkQcA/ApAJYDjAP4eiV+2PDeJX/inAKxU1cvOGH9uAIjI/wbwIwA3AIwA+Ack1rz/E0CVM7ZFVb8q2kEWgYj8F4AlACYBbFfVA1H5mWEpPRFRSJXabYRERJQlBnAiopBiACciCikGcCKikGIAJyIKKQZwIqKQYgAnIgqp/w8xDT7mkSo9wgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqe-gm_gw6Uy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}